{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b616719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchrl.networks.init as init\n",
    "import json\n",
    "import numpy as np\n",
    "from torch.distributions import Distribution, Normal\n",
    "from torchrl.utils import get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca2ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pf explore\n",
    "class TanhNormal(Distribution):\n",
    "    \"\"\"\n",
    "    Basically from RLKIT\n",
    "\n",
    "    Represent distribution of X where\n",
    "        X ~ tanh(Z)\n",
    "        Z ~ N(mean, std)\n",
    "\n",
    "    Note: this is not very numerically stable.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normal_mean, normal_std, epsilon=1e-6):\n",
    "        \"\"\"\n",
    "        :param normal_mean: Mean of the normal distribution\n",
    "        :param normal_std: Std of the normal distribution\n",
    "        :param epsilon: Numerical stability epsilon when computing log-prob.\n",
    "        \"\"\"\n",
    "        self.normal_mean = normal_mean\n",
    "        self.normal_std = normal_std\n",
    "        self.normal = Normal(normal_mean, normal_std)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def sample_n(self, n, return_pre_tanh_value=False):\n",
    "        z = self.normal.sample_n(n)\n",
    "        if return_pre_tanh_value:\n",
    "            return torch.tanh(z), z\n",
    "        else:\n",
    "            return torch.tanh(z)\n",
    "\n",
    "    def log_prob(self, value, pre_tanh_value=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param value: some value, x\n",
    "        :param pre_tanh_value: arctanh(x)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if pre_tanh_value is None:\n",
    "            pre_tanh_value = torch.log(\n",
    "                (1 + value) / (1 - value)\n",
    "            ) / 2\n",
    "        return self.normal.log_prob(pre_tanh_value) - torch.log(\n",
    "            1 - value * value + self.epsilon\n",
    "        )\n",
    "\n",
    "    def sample(self, return_pretanh_value=False):\n",
    "        \"\"\"\n",
    "        Gradients will and should *not* pass through this operation.\n",
    "\n",
    "        See https://github.com/pytorch/pytorch/issues/4620 for discussion.\n",
    "        \"\"\"\n",
    "        z = self.normal.sample().detach()\n",
    "\n",
    "        if return_pretanh_value:\n",
    "            return torch.tanh(z), z\n",
    "        else:\n",
    "            return torch.tanh(z)\n",
    "\n",
    "    def rsample(self, return_pretanh_value=False):\n",
    "        \"\"\"\n",
    "        Sampling in the reparameterization case.\n",
    "        \"\"\"\n",
    "        z = (\n",
    "                self.normal_mean +\n",
    "                self.normal_std *\n",
    "                Normal(\n",
    "                    torch.zeros(self.normal_mean.size()),\n",
    "                    torch.ones(self.normal_std.size())\n",
    "                ).sample().to(self.normal_mean.device)\n",
    "        )\n",
    "\n",
    "        if return_pretanh_value:\n",
    "            return torch.tanh(z), z\n",
    "        else:\n",
    "            return torch.tanh(z)\n",
    "\n",
    "    def entropy(self):\n",
    "        return self.normal.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071ae78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new 2 MLPBaseAE\n",
    "class MLPBaseAE(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_shapes, expert_nums, expert_hidden_shapes, tower_hidden_shapes,\n",
    "                 attention_shapes, activation_func=F.relu, init_func=init.basic_init, last_activation_func=None,\n",
    "                 flag=None, expert_id=None, v_id=None, q_id=None, k_id=None, task_nums = None):\n",
    "        super().__init__()\n",
    "        self.flag = flag\n",
    "        self.activation_func = activation_func\n",
    "        self.fcs = []\n",
    "        if last_activation_func is not None:\n",
    "            self.last_activation_func = last_activation_func\n",
    "        else:\n",
    "            self.last_activation_func = activation_func\n",
    "\n",
    "        if flag == 'baseline':\n",
    "            input_shape = np.prod(input_shape)\n",
    "            self.output_shape = input_shape\n",
    "            for i, next_shape in enumerate(hidden_shapes):\n",
    "                fc = nn.Linear(input_shape, next_shape)\n",
    "                init_func(fc)\n",
    "                self.fcs.append(fc)\n",
    "                # set attr for pytorch to track parameters( device )\n",
    "                self.__setattr__(\"baseline_fc{}\".format(i), fc)\n",
    "\n",
    "                input_shape = next_shape\n",
    "                self.output_shape = next_shape\n",
    "\n",
    "        elif flag == 'expert':\n",
    "            input_shape = hidden_shapes[-1]\n",
    "            self.output_shape = input_shape\n",
    "\n",
    "            for i, next_shape in enumerate(expert_hidden_shapes):\n",
    "                fc = nn.Linear(input_shape, next_shape)\n",
    "                init_func(fc)\n",
    "                self.fcs.append(fc)\n",
    "                # set attr for pytorch to track parameters( device )\n",
    "                self.__setattr__(\"expert{}_fc{}\".format(expert_id, i), fc)\n",
    "\n",
    "                input_shape = next_shape\n",
    "                self.output_shape = next_shape\n",
    "\n",
    "        elif flag == 'tower':\n",
    "            input_shape = attention_shapes\n",
    "            self.output_shape = input_shape\n",
    "\n",
    "            for i, next_shape in enumerate(tower_hidden_shapes):\n",
    "                fc = nn.Linear(input_shape, next_shape)\n",
    "                init_func(fc)\n",
    "                self.fcs.append(fc)\n",
    "                # set attr for pytorch to track parameters( device )\n",
    "                self.__setattr__(\"tower_fc{}\".format(i), fc)\n",
    "\n",
    "                input_shape = next_shape\n",
    "                self.output_shape = next_shape\n",
    "\n",
    "        elif flag == 'attention_v':\n",
    "            input_shape = expert_hidden_shapes[-1]\n",
    "            self.output_shape = input_shape\n",
    "\n",
    "            fc = nn.Linear(input_shape, attention_shapes, bias=False)\n",
    "            # init_func(fc)\n",
    "            self.fcs.append(fc)\n",
    "            # set attr for pytorch to track parameters( device )\n",
    "            self.__setattr__(\"v{}_fc\".format(v_id), fc)\n",
    "\n",
    "            self.output_shape = attention_shapes\n",
    "\n",
    "        elif flag == 'attention_k':\n",
    "            input_shape = expert_hidden_shapes[-1]\n",
    "            self.output_shape = input_shape\n",
    "\n",
    "            fc = nn.Linear(input_shape, attention_shapes, bias=False)\n",
    "            # init_func(fc)\n",
    "            self.fcs.append(fc)\n",
    "            # set attr for pytorch to track parameters( device )\n",
    "            self.__setattr__(\"k{}_fc\".format(k_id), fc)\n",
    "\n",
    "            self.output_shape = attention_shapes\n",
    "\n",
    "        elif flag == 'attention_q':\n",
    "            input_shape = 1\n",
    "            self.output_shape = input_shape\n",
    "\n",
    "            fc = nn.Linear(input_shape, attention_shapes, bias=False)\n",
    "#             init_func(fc)\n",
    "            self.fcs.append(fc)\n",
    "            # set attr for pytorch to track parameters( device )\n",
    "            self.__setattr__(\"q_fc\", fc)\n",
    "\n",
    "            self.output_shape = attention_shapes\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for fc in self.fcs[:-1]:\n",
    "            out = fc(out)\n",
    "            out = self.activation_func(out)\n",
    "        out = self.fcs[-1](out)\n",
    "        if 'attention' not in self.flag:\n",
    "            out = self.last_activation_func(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09321b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 NetAE\n",
    "class NetAE(nn.Module):\n",
    "    def __init__(\n",
    "            self, output_shape,\n",
    "            base_type,\n",
    "            expert_nums,\n",
    "            task_nums,\n",
    "            append_hidden_shapes=[],\n",
    "            append_hidden_init_func=init.basic_init,\n",
    "            net_last_init_func=init.uniform_init,\n",
    "            activation_func=F.relu,\n",
    "            **kwargs):\n",
    "\n",
    "        super().__init__()\n",
    "        self.task_nums = task_nums\n",
    "        self.n = expert_nums\n",
    "        # 0 baseline network 2 layers mlp 300 300\n",
    "        self.base = base_type(activation_func=activation_func, expert_nums=self.n, flag='baseline', **kwargs)\n",
    "        self.activation_func = activation_func\n",
    "\n",
    "        # 1 experts networks 3 * 2 layers mlp 400 400 output\n",
    "        self.mlp_list = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.n):\n",
    "            self.mlp_list.append(\n",
    "                base_type(activation_func=activation_func, expert_nums=self.n, flag='expert', expert_id=i, **kwargs))\n",
    "\n",
    "            # 2 attention module\n",
    "        self.attention_v_list = nn.ModuleList()\n",
    "#         self.attention_q_list = nn.ModuleList()\n",
    "        self.attention_k_list = nn.ModuleList()\n",
    "        for i in range(self.n):\n",
    "            self.attention_v_list.append(\n",
    "                base_type(activation_func=activation_func, expert_nums=self.n, flag='attention_v', v_id=i, **kwargs))\n",
    "            self.attention_k_list.append(\n",
    "                base_type(activation_func=activation_func, expert_nums=self.n, flag='attention_k', k_id=i, **kwargs))\n",
    "        \n",
    "        self.attention_q = base_type(activation_func=activation_func, expert_nums=self.n, flag='attention_q', q_id=i, **kwargs) \n",
    "        self.activation_func = activation_func\n",
    "        #         for i in range(self.task_nums):\n",
    "#             self.attention_q_list.append(\n",
    "#                 base_type(activation_func=activation_func, expert_nums=self.n, flag='attention_q', q_id=i, task_nums = self.task_nums,**kwargs))\n",
    "            # 3 tower network 1 layers mlp 100\n",
    "        self.tower = base_type(activation_func=activation_func, expert_nums=self.n, flag='tower', **kwargs)\n",
    "        self.activation_func = activation_func\n",
    "\n",
    "        #         append_input_shape = self.experts.output_shape\n",
    "\n",
    "        #         self.append_fcs = []\n",
    "        #         for i, next_shape in enumerate(append_hidden_shapes):\n",
    "        #             fc = nn.Linear(append_input_shape, next_shape)\n",
    "        #             append_hidden_init_func(fc)\n",
    "        #             self.append_fcs.append(fc)\n",
    "        #             # set attr for pytorch to track parameters( device )\n",
    "        #             self.__setattr__(\"append_fc{}\".format(i), fc)\n",
    "        #             append_input_shape = next_shape\n",
    "\n",
    "        # 4 last network\n",
    "        self.last = nn.Linear(self.tower.output_shape, output_shape)\n",
    "        net_last_init_func(self.last)\n",
    "\n",
    "    def forward(self, x, task_id):\n",
    "        # 0 baseline network\n",
    "        out = self.base(x)\n",
    "\n",
    "        expkqs = []\n",
    "        vs = []\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            # 1 expert networks\n",
    "            e = self.mlp_list[i](out)\n",
    "            # 2 attention module\n",
    "            v = self.attention_v_list[i](e)\n",
    "            k = self.attention_k_list[i](e)\n",
    "#             q = self.attention_q_list[task_id.item()](task_idx)\n",
    "            q = self.attention_q(task_id)\n",
    "    \n",
    "            expkq = torch.sum(torch.mul(k, q),dim=-1)\n",
    "            expkqs.append(expkq)\n",
    "            print('expkq',expkq.shape)\n",
    "            vs.append(v)\n",
    "\n",
    "        res = torch.zeros(vs[0].shape).to('cuda:0')\n",
    "        alphas = [i / sum(expkqs) for i in expkqs]\n",
    "\n",
    "        for i in range(self.n):\n",
    "            res += vs[i] * alphas[i].unsqueeze(-1)\n",
    "\n",
    "        # 3 tower network\n",
    "        out = self.tower(res)\n",
    "\n",
    "        #         for append_fc in self.append_fcs:\n",
    "        #             out = append_fc(out)\n",
    "        #             out = self.activation_func(out)\n",
    "\n",
    "        # 4 last network\n",
    "        out = self.last(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f5b7dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义三维数组和二维数组\n",
    "arr_3d = torch.ones((2, 2, 5))\n",
    "arr_2d = torch.ones((2, 2))\n",
    "\n",
    "# 将二维数组扩展为(2, 2, 1)的三维数组\n",
    "arr_2d = arr_2d.unsqueeze(2)\n",
    "\n",
    "# 沿5方向的每一面对应乘上二维数组\n",
    "result = arr_3d * arr_2d\n",
    "\n",
    "# 查看结果\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d5a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 GrassianContPolicyAE\n",
    "LOG_SIG_MAX = 2\n",
    "LOG_SIG_MIN = -20\n",
    "\n",
    "\n",
    "class GuassianContPolicyAE(NetAE):\n",
    "    def forward(self, x, task_id):\n",
    "        qs = super().forward(x, task_id)\n",
    "\n",
    "        #         mean, log_std = x.chunk(2, dim=-1)\n",
    "\n",
    "        #         log_std = torch.clamp(log_std, LOG_SIG_MIN, LOG_SIG_MAX)\n",
    "        #         std = torch.exp(log_std)\n",
    "\n",
    "        # return mean, std, log_std\n",
    "        return qs\n",
    "\n",
    "    def eval_act(self, x):\n",
    "        with torch.no_grad():\n",
    "            mean, _, _ = self.forward(x)\n",
    "        return torch.tanh(mean.squeeze(0)).detach().cpu().numpy()\n",
    "\n",
    "    def explore(self, x, return_log_probs=False, return_pre_tanh=False):\n",
    "\n",
    "        mean, std, log_std = self.forward(x)\n",
    "\n",
    "        dis = TanhNormal(mean, std)\n",
    "\n",
    "        ent = dis.entropy().sum(-1, keepdim=True)\n",
    "\n",
    "        dic = {\n",
    "            \"mean\": mean,\n",
    "            \"log_std\": log_std,\n",
    "            \"ent\": ent\n",
    "        }\n",
    "\n",
    "        if return_log_probs:\n",
    "            action, z = dis.rsample(return_pretanh_value=True)\n",
    "            log_prob = dis.log_prob(\n",
    "                action,\n",
    "                pre_tanh_value=z\n",
    "            )\n",
    "            log_prob = log_prob.sum(dim=-1, keepdim=True)\n",
    "            dic[\"pre_tanh\"] = z.squeeze(0)\n",
    "            dic[\"log_prob\"] = log_prob\n",
    "        else:\n",
    "            if return_pre_tanh:\n",
    "                action, z = dis.rsample(return_pretanh_value=True)\n",
    "                dic[\"pre_tanh\"] = z.squeeze(0)\n",
    "            action = dis.rsample(return_pretanh_value=False)\n",
    "\n",
    "        dic[\"action\"] = action.squeeze(0)\n",
    "        return dic\n",
    "\n",
    "    def update(self, obs, actions):\n",
    "        mean, std, log_std = self.forward(obs)\n",
    "        dis = TanhNormal(mean, std)\n",
    "\n",
    "        log_prob = dis.log_prob(actions).sum(-1, keepdim=True)\n",
    "        ent = dis.entropy().sum(-1, keepdim=True)\n",
    "\n",
    "        out = {\n",
    "            \"mean\": mean,\n",
    "            \"log_std\": log_std,\n",
    "            \"log_prob\": log_prob,\n",
    "            \"ent\": ent\n",
    "        }\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6fe3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros((4,4)).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "800ed070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expkq torch.Size([])\n",
      "expkq torch.Size([])\n",
      "expkq torch.Size([])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0023, -0.0018, -0.0003,  0.0010,  0.0030,  0.0047,  0.0009, -0.0006],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = get_params('./meta_config/mt10/mtsac_ae.json')\n",
    "params['net']['base_type'] = MLPBaseAE\n",
    "\n",
    "obs = torch.rand((19)).float().to('cuda:0')\n",
    "action = torch.rand((4,)).float().to('cuda:0')\n",
    "task_id = torch.tensor(([6])).float().to('cuda:0')\n",
    "pf = GuassianContPolicyAE(\n",
    "        input_shape=19,\n",
    "        output_shape=2 * 4,\n",
    "        **params['net'])\n",
    "\n",
    "pf.to('cuda:0')\n",
    "pf.forward(obs,task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e59654a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6292, 0.9095, 0.0874, 0.3740],\n",
       "        [0.3330, 0.8461, 0.2225, 0.2676],\n",
       "        [0.0229, 0.1489, 0.4175, 0.3487]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e4344b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[53, 62],\n",
      "        [71, 80]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义两个3x2x2的三维矩阵\n",
    "a = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]])\n",
    "b = torch.tensor([[[2, 2], [2, 2]], [[3, 3], [3, 3]], [[4, 4], [4, 4]]])\n",
    "\n",
    "# 对应位置元素相乘\n",
    "c = torch.mul(a, b)\n",
    "\n",
    "# 输出结果\n",
    "print(torch.sum(c,dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "81593f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['base.baseline_fc0.weight', 'base.baseline_fc0.bias', 'base.baseline_fc1.weight', 'base.baseline_fc1.bias', 'mlp_list.0.expert0_fc0.weight', 'mlp_list.0.expert0_fc0.bias', 'mlp_list.0.expert0_fc1.weight', 'mlp_list.0.expert0_fc1.bias', 'mlp_list.1.expert1_fc0.weight', 'mlp_list.1.expert1_fc0.bias', 'mlp_list.1.expert1_fc1.weight', 'mlp_list.1.expert1_fc1.bias', 'mlp_list.2.expert2_fc0.weight', 'mlp_list.2.expert2_fc0.bias', 'mlp_list.2.expert2_fc1.weight', 'mlp_list.2.expert2_fc1.bias', 'attention_v_list.0.v0_fc.weight', 'attention_v_list.1.v1_fc.weight', 'attention_v_list.2.v2_fc.weight', 'attention_q_list.0.q0_fc.weight', 'attention_q_list.1.q1_fc.weight', 'attention_q_list.2.q2_fc.weight', 'attention_q_list.3.q3_fc.weight', 'attention_q_list.4.q4_fc.weight', 'attention_q_list.5.q5_fc.weight', 'attention_q_list.6.q6_fc.weight', 'attention_q_list.7.q7_fc.weight', 'attention_q_list.8.q8_fc.weight', 'attention_q_list.9.q9_fc.weight', 'attention_k_list.0.k0_fc.weight', 'attention_k_list.1.k1_fc.weight', 'attention_k_list.2.k2_fc.weight', 'tower.tower_fc0.weight', 'tower.tower_fc0.bias', 'tower.tower_fc1.weight', 'tower.tower_fc1.bias', 'last.weight', 'last.bias'])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca03578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# critics:\n",
    "class FlattenNetAE(NetAE):\n",
    "    def forward(self, input,task_id):\n",
    "        out = torch.cat(input, dim = -1)\n",
    "        return super().forward(out,task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73763091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0009], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qf1 = FlattenNetAE(\n",
    "        input_shape=23,\n",
    "        output_shape=1,\n",
    "        **params['net'])\n",
    "qf1.forward([obs,action],task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d07030e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "batch ={'task_idxs':torch.tensor([5])}\n",
    "task_idx_num = batch['task_idxs'].item()\n",
    "task_idx = torch.zeros((10,))\n",
    "task_idx[task_idx_num]=1\n",
    "print(task_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112039c4",
   "metadata": {},
   "source": [
    "搞错了，应该用BootstrappedNet更好。我们试试看。首先看看BootstrapNet原版："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b450483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "            self, output_shape,\n",
    "            base_type,\n",
    "            append_hidden_shapes=[],\n",
    "            append_hidden_init_func=init.basic_init,\n",
    "            net_last_init_func=init.uniform_init,\n",
    "            activation_func=F.relu,\n",
    "            **kwargs):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.base = base_type(activation_func=activation_func, **kwargs)\n",
    "        self.activation_func = activation_func\n",
    "        append_input_shape = self.base.output_shape\n",
    "        self.append_fcs = []\n",
    "        for i, next_shape in enumerate(append_hidden_shapes):\n",
    "            fc = nn.Linear(append_input_shape, next_shape)\n",
    "            append_hidden_init_func(fc)\n",
    "            self.append_fcs.append(fc)\n",
    "            # set attr for pytorch to track parameters( device )\n",
    "            self.__setattr__(\"append_fc{}\".format(i), fc)\n",
    "            append_input_shape = next_shape\n",
    "\n",
    "        self.last = nn.Linear(append_input_shape, output_shape)\n",
    "        net_last_init_func(self.last)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.base(x)\n",
    "\n",
    "        for append_fc in self.append_fcs:\n",
    "            out = append_fc(out)\n",
    "            out = self.activation_func(out)\n",
    "\n",
    "        out = self.last(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a2f6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBase(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_shapes, activation_func=F.relu, init_func = init.basic_init, last_activation_func = None ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.activation_func = activation_func\n",
    "        self.fcs = []\n",
    "        if last_activation_func is not None:\n",
    "            self.last_activation_func = last_activation_func\n",
    "        else:\n",
    "            self.last_activation_func = activation_func\n",
    "        input_shape = np.prod(input_shape)\n",
    "\n",
    "        self.output_shape = input_shape\n",
    "        for i, next_shape in enumerate( hidden_shapes ):\n",
    "            fc = nn.Linear(input_shape, next_shape)\n",
    "            init_func(fc)\n",
    "            self.fcs.append(fc)\n",
    "            # set attr for pytorch to track parameters( device )\n",
    "            self.__setattr__(\"fc{}\".format(i), fc)\n",
    "\n",
    "            input_shape = next_shape\n",
    "            self.output_shape = next_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = x\n",
    "        for fc in self.fcs[:-1]:\n",
    "            out = fc(out)\n",
    "            out = self.activation_func(out)\n",
    "        out = self.fcs[-1](out)\n",
    "        out = self.last_activation_func(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "669c3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BootstrappedNet(Net):\n",
    "    def __init__(self, output_shape, \n",
    "                 head_num = 10,\n",
    "                 **kwargs ):\n",
    "        self.head_num = head_num\n",
    "        self.origin_output_shape = output_shape\n",
    "        output_shape *= self.head_num\n",
    "        super().__init__(output_shape = output_shape, **kwargs)\n",
    "\n",
    "    def forward(self, x, idx):\n",
    "        base_shape = x.shape[:-1]\n",
    "        print(base_shape)\n",
    "        out = super().forward(x)# 8*10\n",
    "        out_shape = base_shape + torch.Size([self.origin_output_shape, self.head_num])\n",
    "        print(out_shape,torch.Size([self.origin_output_shape, self.head_num]))\n",
    "        view_idx_shape = base_shape + torch.Size([1, 1])\n",
    "        print(base_shape)\n",
    "        expand_idx_shape = base_shape + torch.Size([self.origin_output_shape, 1])\n",
    "        print(base_shape,torch.Size([self.origin_output_shape, 1]))\n",
    "        \n",
    "        out = out.reshape(out_shape)\n",
    "\n",
    "        idx = idx.view(view_idx_shape)\n",
    "        idx = idx.expand(expand_idx_shape)\n",
    "\n",
    "        out = out.gather(-1, idx).squeeze(-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "41589e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([8, 10]) torch.Size([8, 10])\n",
      "torch.Size([])\n",
      "torch.Size([]) torch.Size([8, 1])\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 6.0238e-03, -4.7925e-04,  2.1551e-03,  6.3379e-03, -3.2525e-03,\n",
       "         2.4140e-03, -6.3365e-06,  1.2156e-03], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = get_params('./meta_config/mt10/mtmhsac.json')\n",
    "params['net']['base_type'] = MLPBase\n",
    "pf = BootstrappedNet (\n",
    "        input_shape = 19, \n",
    "        output_shape = 2 * 4,\n",
    "        head_num=10,\n",
    "        **params['net'] )\n",
    "obs = torch.rand((19,))\n",
    "\n",
    "pf2 = Net(input_shape = 19, \n",
    "        output_shape = 2 * 4,\n",
    "        **params['net'] )\n",
    "\n",
    "pf.forward(obs,torch.tensor([1]))\n",
    "pf2.forward(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57e43127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 19, 10)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(out_shape)\n\u001b[1;32m      4\u001b[0m view_idx_shape \u001b[38;5;241m=\u001b[39m base_shape \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m expand_idx_shape \u001b[38;5;241m=\u001b[39m base_shape \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39morigin_output_shape, \u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "base_shape = (19,)\n",
    "out_shape = base_shape + torch.Size([19, 10])\n",
    "print(out_shape)\n",
    "view_idx_shape = base_shape + torch.Size([1, 1])\n",
    "expand_idx_shape = base_shape + torch.Size([self.origin_output_shape, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9c540",
   "metadata": {},
   "source": [
    "## 好的，现在来弄一下我们自己的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a73f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BootstrappedNetAE(NetAE):\n",
    "    def __init__(self, output_shape, \n",
    "                 head_num = 10,\n",
    "                 **kwargs ):\n",
    "        self.head_num = head_num\n",
    "        self.origin_output_shape = output_shape\n",
    "        output_shape *= self.head_num\n",
    "        super().__init__(output_shape = output_shape, **kwargs)\n",
    "\n",
    "    def forward(self, x, idx):\n",
    "        base_shape = x.shape[:-1]\n",
    "        print(base_shape)\n",
    "        out = super().forward(x)# 8*10\n",
    "        out_shape = base_shape + torch.Size([self.origin_output_shape, self.head_num])\n",
    "        print(out_shape,torch.Size([self.origin_output_shape, self.head_num]))\n",
    "        view_idx_shape = base_shape + torch.Size([1, 1])\n",
    "        print(base_shape)\n",
    "        expand_idx_shape = base_shape + torch.Size([self.origin_output_shape, 1])\n",
    "        print(base_shape,torch.Size([self.origin_output_shape, 1]))\n",
    "        \n",
    "        out = out.reshape(out_shape)\n",
    "\n",
    "        idx = idx.view(view_idx_shape)\n",
    "        idx = idx.expand(expand_idx_shape)\n",
    "\n",
    "        out = out.gather(-1, idx).squeeze(-1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bba90772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8168, 0.6146, 0.2686, 0.3414, 0.0517, 0.3150, 0.1318, 0.7991, 0.1808,\n",
      "         0.8374]])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "view() received an invalid combination of arguments - got (), but expected one of:\n * (torch.dtype dtype)\n * (tuple of ints size)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[0;32m----> 3\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: view() received an invalid combination of arguments - got (), but expected one of:\n * (torch.dtype dtype)\n * (tuple of ints size)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((1,10))\n",
    "print(a)\n",
    "a.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452dafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soft-module",
   "language": "python",
   "name": "soft-module"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
